# Credit Score Movement Prediction ML Project

## ğŸ¯ Project Overview

This project implements a comprehensive machine learning solution for predicting credit score movements using synthetic credit behavior data. The solution provides actionable insights for risk management and customer engagement strategies.

## ğŸ“Š Key Features

- **Synthetic Dataset Generation**: 25,000+ customer-month records with realistic credit behavior patterns
- **Multi-class Classification**: Predicts credit score movement (increase, decrease, stable)
- **Multiple ML Models**: RandomForest and XGBoost with hyperparameter tuning
- **Explainability Analysis**: SHAP values for model interpretability
- **Business Insights**: Risk segmentation and actionable recommendations

## ğŸš€ Quick Start

### Prerequisites
- Python 3.7+
- Jupyter Notebook

### Installation

1. **Clone or download the project files**

2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Launch Jupyter Notebook**:
   ```bash
   jupyter notebook
   ```

4. **Open and run the notebook**:
   - Open `credit_scoring_ml_project.ipynb`
   - Run all cells sequentially

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ credit_scoring_ml_project.ipynb  # Main notebook with complete analysis
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ README.md                       # This file
â””â”€â”€ synthetic_credit_dataset.csv    # Generated dataset (after running notebook)
```

## ğŸ” Analysis Overview

### 1. Data Generation
- Creates 25,000 synthetic customer records
- Features include demographics, financial metrics, and credit history
- Realistic correlations between features

### 2. Target Variable Logic
- **DECREASE**: High risk indicators (high DPD, high utilization, poor repayment history)
- **INCREASE**: Low risk indicators (excellent repayment, low utilization, manageable EMI)
- **STABLE**: Moderate risk profile

### 3. Exploratory Data Analysis
- Feature distributions and correlations
- Target class analysis
- Risk factor identification

### 4. Model Development
- RandomForest and XGBoost classifiers
- GridSearchCV hyperparameter tuning
- SMOTE for class imbalance handling

### 5. Model Evaluation
- Comprehensive metrics (accuracy, F1-macro, F1-micro)
- Confusion matrices and classification reports
- Model comparison and selection

### 6. Explainability
- SHAP analysis for feature importance
- Individual prediction explanations
- Business-relevant insights

### 7. Business Recommendations
- Risk segmentation analysis
- Targeted intervention strategies
- Actionable business insights

## ğŸ“ˆ Key Results

### Model Performance
- **Best Model**: [Determined during execution]
- **Test Accuracy**: ~85-90% (varies by run)
- **F1-Macro Score**: ~0.80-0.85

### Risk Segments Identified
1. **High-Risk (Decrease)**: ~15-20% of customers
2. **High-Opportunity (Increase)**: ~25-30% of customers  
3. **Stable**: ~50-60% of customers

### Top Risk Factors
1. Credit utilization ratio
2. Repayment history score
3. Days past due
4. EMI-to-income ratio
5. Number of hard inquiries

## ğŸ’¡ Business Interventions

### High-Risk Segment
- **Proactive Credit Counseling Program**
- **Emergency Hardship Relief Program**

### High-Opportunity Segment  
- **Premium Rewards & Upselling Program**
- **Credit Limit Enhancement Initiative**

### Stable Segment
- **Engagement & Retention Program**
- **Predictive Monitoring System**

## ğŸ› ï¸ Technical Details

### Dependencies
- **pandas**: Data manipulation and analysis
- **numpy**: Numerical computing
- **scikit-learn**: Machine learning algorithms
- **xgboost**: Gradient boosting framework
- **shap**: Model explainability
- **matplotlib/seaborn**: Data visualization
- **imbalanced-learn**: Handling imbalanced datasets

### Model Features
- Feature engineering (ratios, flags, indicators)
- One-hot encoding for categorical variables
- Standard scaling for numerical features
- SMOTE oversampling for class balance

## ğŸ“‹ Output Files

After running the notebook, you'll have:
- `synthetic_credit_dataset.csv`: Generated dataset
- Comprehensive analysis and visualizations
- Model performance metrics
- Business recommendations

## ğŸ”§ Customization

You can easily modify:
- **Dataset size**: Change `n_samples` parameter
- **Feature logic**: Adjust heuristics in target variable creation
- **Model parameters**: Modify hyperparameter grids
- **Business rules**: Update risk thresholds and segments

## ğŸ“ Next Steps

1. **Deploy Model**: Implement in production environment
2. **Monitor Performance**: Set up real-time model monitoring
3. **A/B Testing**: Test intervention strategies
4. **Model Retraining**: Update quarterly with new data
5. **Feature Expansion**: Add more predictive features

## ğŸ¤ Contributing

This is a self-contained educational project. Feel free to:
- Experiment with different models
- Add new features or business rules
- Modify visualization styles
- Extend analysis to other risk metrics

## ğŸ“ License

This project is for educational and demonstration purposes. Use responsibly and ensure compliance with relevant regulations when working with real financial data.

---

**Note**: This project uses synthetic data generated for demonstration purposes. Always ensure proper data governance and regulatory compliance when working with real customer financial data. 